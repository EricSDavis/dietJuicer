#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import pandas as pd
import glob

##### Load config and sample sheets #####

configfile: "config/config.yaml"

onsuccess:
	print("alignFASTQ completed successfully!")

##### Define rules #####
rule all:
	input:
		expand('output/{prefix}_merge_{extension}.bam', prefix=config["prefix"], extension=['collisions', 'collisions_low_mapq', 'unmapped', 'mapq0']),
		expand('output/{prefix}_dedupAlignablePart3_alignable.bam', prefix=config["prefix"]),
		expand('output/{prefix}_dupStats_stats_dups{extension}', prefix=config["prefix"], extension=['.txt', '_hists.m']),
		expand('output/{prefix}_inter.txt', prefix=config["prefix"]),
		expand('output/{prefix}_inter_30.txt', prefix=config["prefix"])

rule countLigations:
	input:
		R1 = lambda wildcards: ['output/splitsR1/{sample}_R1.fastq.gz'.format(sample=wildcards.sample)],
		R2 = lambda wildcards: ['output/splitsR2/{sample}_R2.fastq.gz'.format(sample=wildcards.sample)]
	output:
		temp = temp('output/{prefix}_countLigations_split{sample}_temp'),
		res = 'output/{prefix}_countLigations_split{sample}_norm.txt.res.txt',
		linecount = 'output/{prefix}_countLigations_split{sample}_linecount.txt'
	log:
		err = "output/logs/{prefix}_countLigations_split{sample}.err",
		out = "output/logs/{prefix}_countLigations_split{sample}.out"
	params:
		ligation = config['countLigations']['ligation']
	benchmark: 
		'output/benchmarks/{prefix}_countLigations_split{sample}.tsv'
	shell:
		"R1={input.R1} R2={input.R2} ligation={params.ligation} temp={output.temp} res={output.res} linecount={output.linecount} sh scripts/countLigations.sh 2> {log.err} 1> {log.out}"

rule align:
	input:
		R1 = lambda wildcards: ['output/splitsR1/{sample}_R1.fastq.gz'.format(sample=wildcards.sample)],
		R2 = lambda wildcards: ['output/splitsR2/{sample}_R2.fastq.gz'.format(sample=wildcards.sample)]
	output:
		sam = temp("output/{prefix}_align_split{sample}.sam") ## Make temporary
	log:
		err = "output/logs/{prefix}_align_split{sample}.err"
	threads: 4
	params:
		fasta = config['fasta']
	benchmark: 
		"output/benchmarks/{prefix}_align_split{sample}.tsv"
	shell:
		"module load bwa; "
		"bwa mem -SP5M -t {threads} {params.fasta} {input.R1} {input.R2} > {output.sam} 2> {log.err}"

rule chimera:
	input:
		sam = rules.align.output.sam
	output:
		norm = "output/{prefix}_align_split{sample}_norm.txt",
		alignable = temp("output/{prefix}_align_split{sample}_alignable.sam"), ## Make temporary
		collisions = temp("output/{prefix}_align_split{sample}_collisions.sam"), ## Make temporary
		lowqcollisions = temp("output/{prefix}_align_split{sample}_collisions_low_mapq.sam"), ## Make temporary
		unmapped = temp("output/{prefix}_align_split{sample}_unmapped.sam"), ## Make temporary
		mapq0 = temp("output/{prefix}_align_split{sample}_mapq0.sam"), ## Make temporary
		unpaired = temp("output/{prefix}_align_split{sample}_unpaired.sam") ## Make temporary
	threads: 1
	params:
		fname = 'output/{prefix}_align_split{sample}',
		mapq0_reads_included = config['chimera']['mapq0_reads_included']
	benchmark: 
		'output/benchmarks/{prefix}_chimera_split{sample}.tsv'
	run:
		shell('touch {output}')
		shell('gawk -v "fname"={params.fname} -v "mapq0_reads_included"={params.mapq0_reads_included} -f ./scripts/chimeric_blacklist.awk {input.sam}')

rule fragment:
	input:
		norm = rules.chimera.output.norm
	output:
		frag = "output/{prefix}_fragment_split{sample}.frag.txt",
	threads: 1
	params:
		site = config['site'],
		site_file = config['site_file']
	benchmark:
		'output/benchmarks/{prefix}_fragment_split{sample}.tsv'
	shell: ## Use better error handling with the if/else statement for restriction site
		"""
		if [ {params.site} != "none" ]
		then
				./scripts/fragment.pl {input.norm} {output.frag} {params.site_file}    
		else
				awk '{{printf("%s %s %s %d %s %s %s %d", $1, $2, $3, 0, $4, $5, $6, 1); for (i=7; i<=NF; i++) {{printf(" %s",$i);}}printf("\n");}}' {input.norm} > {output.frag}
		fi
		"""

rule sam2bam:
	input:
		lambda wildcards: ['output/{prefix}_align_split{sample}_{extension}.sam'.format(prefix=wildcards.prefix, sample=wildcards.sample, extension=wildcards.extension)]
	output:
		'output/{prefix}_sam2bam_split{sample}_{extension}.bam'
	benchmark:
		'output/benchmarks/{prefix}_fragment_split{sample}_{extension}.tsv'
	shell:
		'module load samtools; '
		'samtools view -hb {input} > {output}'

rule sort:
	input:
		rules.fragment.output.frag
	output:
		sorted = "output/{prefix}_sort_split{sample}.sort.txt"
	threads: 1
	shadow: "minimal"
	benchmark:
		'output/benchmarks/{prefix}_sort_split{sample}.tsv'
	run:
		shell('sort -k2,2d -k6,6d -k4,4n -k8,8n -k1,1n -k5,5n -k3,3n {input} > {output.sorted}')

rule merge:
	input:
		lambda wildcards: expand('output/{prefix}_sam2bam_split{sample}_{extension}.bam', prefix=config["prefix"], sample=glob_wildcards('output/splitsR1/{sample}_R1.fastq.gz').sample, extension=wildcards.extension)
	output:
		'output/{prefix}_merge_{extension}.bam'
	log:
		err = "output/logs/{prefix}_merge_{extension}.err"
	threads: 1
	benchmark:
		'output/benchmarks/{prefix}_merge_{extension}.tsv'
	shell:
		'module load samtools; '
		'samtools merge -n {output} {input} 2> {log.err}'

rule mergedSort:
	input:
		expand('output/{prefix}_sort_split{sample}.sort.txt', prefix=config["prefix"], sample=glob_wildcards('output/splitsR1/{sample}_R1.fastq.gz').sample)
	output:
		'output/{prefix}_mergedSort_merged_sort.txt'
	threads: 1
	shadow: "minimal"
	benchmark:
		'output/benchmarks/{prefix}_mergedSort.tsv'
	run:
		shell('sort -m -k2,2d -k6,6d -k4,4n -k8,8n -k1,1n -k5,5n -k3,3n {input} > {output}')

rule dedup:
	input:
		rules.mergedSort.output
	output:
		dups = "output/{prefix}_dedup_dups.txt",
		merged_nodups = "output/{prefix}_dedup_merged_nodups.txt",
		optdups = "output/{prefix}_dedup_opt_dups.txt"
	params:
		name = 'output/{prefix}_'
	threads: 1
	benchmark:
		'output/benchmarks/{prefix}_dedup.tsv'
	run:
		shell('touch {output}'),
		shell('awk -f ./scripts/dups.awk -v name={params.name} {input}')

rule dedupAlignablePart1:
	input:
		rules.dedup.output.merged_nodups
	output:
		temp('output/{prefix}_align_split{sample}_dedup') ## Make temporary
	threads: 1
	benchmark:
		'output/benchmarks/{prefix}_dedupAlignablePart1_split{sample}.tsv'
	shell:
		"""
		awk '{{split($(NF-1), a, "$"); split($NF, b, "$"); print a[3],b[3] > a[2]"_dedup"}}' {input}
		"""

rule dedupAlignablePart2:
	input:
		dedup = rules.dedupAlignablePart1.output,
		alignable = rules.chimera.output.alignable
	output:
		dedup_sam = 'output/{prefix}_align_split{sample}_alignable_dedup.sam',
		bam = 'output/{prefix}_align_split{sample}_alignable.bam'
	threads: 1
	benchmark:
		'output/benchmarks/{prefix}_dedupAlignablePart2_split{sample}.tsv'
	shell:
		"""
		module load samtools
		awk 'BEGIN{{OFS="\t"}}FNR==NR{{for (i=$1; i<=$2; i++){{a[i];}} next}}(!(FNR in a) && $1 !~ /^@/){{$2=or($2,1024)}}{{print}}' {input.dedup} {input.alignable} > {output.dedup_sam}
		samtools view -hb {input.alignable} > {output.bam}
		"""

rule dedupAlignablePart3:
	input:
		lambda wildcards: expand('output/{prefix}_align_split{sample}_alignable.bam', prefix=config["prefix"], sample=glob_wildcards('output/splitsR1/{sample}_R1.fastq.gz').sample)
	output:
		'output/{prefix}_dedupAlignablePart3_alignable.bam'
	log:
		err = "output/logs/{prefix}_dedupAlignablePart3_alignable.err"
	threads: 1
	benchmark:
		'output/benchmarks/{prefix}_dedupAlignablePart3.tsv'
	shell:
		'module load samtools; '
		'samtools merge -n {output} {input} 2> {log.err}'

rule dupStats:
	input:
		rules.dedup.output.dups
	output:
		stats_dups = 'output/{prefix}_dupStats_stats_dups.txt',
		hists = 'output/{prefix}_dupStats_stats_dups_hists.m'
	params:
		site = config['site'],
		site_file = config['site_file']
	threads: 1
	benchmark:
		'output/benchmarks/{prefix}_dupStats.tsv'
	run:
		shell('./scripts/statistics.pl -s {params.site_file} -l {params.site} -o {output.stats_dups} {input}')

rule inter:
	input:
		res = expand('output/{prefix}_countLigations_split{sample}_norm.txt.res.txt', prefix=config["prefix"], sample=glob_wildcards('output/splitsR1/{sample}_R1.fastq.gz').sample),
		merged_nodups = rules.dedup.output.merged_nodups
	output:
		'output/{prefix}_inter.txt'
	params:
		site = config['site'],
		site_file = config['site_file']
	threads: 1
	benchmark:
		'output/benchmarks/{prefix}_inter.tsv'
	shell:
		"""
		cat {input.res} | awk -f ./scripts/stats_sub.awk > {output}
		./scripts/juicer_tools LibraryComplexity output {output} >> {output}
		./scripts/statistics.pl -s {params.site_file} -l {params.site} -o {output} -q 1 {input.merged_nodups}
		"""

rule inter30:
	input:
		res = expand('output/{prefix}_countLigations_split{sample}_norm.txt.res.txt', prefix=config["prefix"], sample=glob_wildcards('output/splitsR1/{sample}_R1.fastq.gz').sample),
		merged_nodups = rules.dedup.output.merged_nodups
	output:
		'output/{prefix}_inter_30.txt'
	params:
		site = config['site'],
		site_file = config['site_file']
	threads: 1
	benchmark:
		'output/benchmarks/{prefix}_inter30.tsv'
	shell:
		"""
		cat {input.res} | awk -f ./scripts/stats_sub.awk > {output}
		./scripts/juicer_tools LibraryComplexity output {output} >> {output}
		./scripts/statistics.pl -s {params.site_file} -l {params.site} -o {output} -q 30 {input.merged_nodups}
		"""